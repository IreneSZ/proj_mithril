{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare data\n",
    "#choose different n for prediction of T+n; label response series accordingly\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"merged.csv\")\n",
    "df['ret'] = df['close'].pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare the labels\n",
    "#label1: predict buy(1) or sell(-1) for T+14 days\n",
    "change14= df['close'].pct_change(14)\n",
    "\n",
    "#make 3 dataframes for the 3 models\n",
    "data = df[['volume','close-open_%of_close','high-low_%of_close',\n",
    "       'macd', '50d_avg', '100d_avg', '200d_avg', 'so', 'oil', 'gold',\n",
    "       'vix','ust10', 'ust5vs2', 'ust10vs2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shiyun/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "data14 = data\n",
    "data14['change'] = change14[14:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shiyun/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/shiyun/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "data14['label'] = np.where(data14['change']>=0, 1, -1)\n",
    "data14.dropna(inplace=True)\n",
    "print(data14.isnull().values.ravel().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['volume', 'close-open_%of_close', 'high-low_%of_close', 'macd',\n",
       "       '50d_avg', '100d_avg', '200d_avg', 'so', 'oil', 'gold', 'vix', 'ust10',\n",
       "       'ust5vs2', 'ust10vs2', 'change', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data14.head()\n",
    "data14.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x14 = data14[['volume', 'close-open_%of_close', 'high-low_%of_close', 'macd',\n",
    "       '50d_avg', '100d_avg', '200d_avg', 'so', 'oil', 'gold', 'vix', 'ust10',\n",
    "       'ust5vs2', 'ust10vs2']]\n",
    "y14 = data14['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x14.to_csv(\"x14.csv\")\n",
    "y14.to_csv('y14.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_block(x, win_size=60):\n",
    "    ret = list()\n",
    "    for i in range(win_size, len(x)):\n",
    "        ret.append(x[i - win_size:i])\n",
    "    return np.stack(ret, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shiyun/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5, 14)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = pd.read_csv('x14.csv', index_col=0).head(5)\n",
    "k.as_matrix().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genfromtxt(x_filename, y_filename, win_size):\n",
    "    \n",
    "    X = pd.read_csv(x_filename, index_col=0).values\n",
    "    X = (X - X.mean(axis=-1, keepdims=True)) / X.std(axis=-1, keepdims=True)\n",
    "    Y = pd.read_csv(y_filename, index_col=0, header=None).values\n",
    "    Y[Y==-1]=0\n",
    "    \n",
    "    ret_X, ret_Y = list(), list()\n",
    "    for i in range(win_size, len(X)-1):\n",
    "        ret_X.append(X[i - win_size:i])\n",
    "        ret_Y.append(Y[i+1])\n",
    "    ret_X = np.stack(ret_X, axis=0).reshape(-1,1,win_size,X.shape[1])\n",
    "    ret_Y = np.stack(ret_Y, axis=0).reshape(-1,Y.shape[1])\n",
    "    \n",
    "    # normalize\n",
    "\n",
    "    \n",
    "    return ret_X, ret_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_X, ret_Y = genfromtxt('x14.csv', 'y14.csv', 60)\n",
    "X_train = ret_X[:3000,...]\n",
    "y_train = ret_Y[:3000,...]\n",
    "X_test = ret_X[3600:,...]\n",
    "y_test = ret_Y[3600:,...]\n",
    "X_dev = ret_X[3000:3600]\n",
    "y_dev = ret_Y[3000:3600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "682"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_data(inputs, labels):\n",
    "    return torch.from_numpy(inputs).float(), torch.from_numpy(labels).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = wrap_data(X_test, y_test)\n",
    "X_dev, y_dev = wrap_data(X_dev, y_dev)\n",
    "X_train, y_train = wrap_data(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert data to tensor\n",
    "test_dataset = Data.TensorDataset(\n",
    "    X_train.float(),\n",
    "    y_train.long())\n",
    "\n",
    "train_dataset = Data.TensorDataset(\n",
    "    X_train.float(),\n",
    "    y_train.long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input pipeline\n",
    "input_size = 18\n",
    "hidden_size1 = 30\n",
    "hidden_size2 = 30\n",
    "num_classes = 2\n",
    "num_epochs = 2\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = (-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, \n",
    "                 channels_in, \n",
    "                 channels_out1, \n",
    "                 channels_out2,\n",
    "                 kernel_size1,\n",
    "                 kernel_size2,\n",
    "                 hid_size1,\n",
    "                 hid_size2):\n",
    "        super(Net, self).__init__()\n",
    "        self.channels_in = channels_in\n",
    "        self.channels_out1 = channels_out1\n",
    "        self.channels_out2 = channels_out2\n",
    "        self.kernel_size1 = kernel_size1\n",
    "        self.kernel_size2 = kernel_size2\n",
    "        self.hid_size1 = hid_size1\n",
    "        self.hid_size2 = hid_size2\n",
    "        \n",
    "        \n",
    "        assert self.kernel_size1 % 2 == 1, 'must be odd'\n",
    "        assert self.kernel_size2 % 2 == 1, 'must be odd'\n",
    "        self.conv1 = nn.Conv2d(self.channels_in, self.channels_out1 , self.kernel_size1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(self.channels_out1, self.channels_out2, self.kernel_size2)\n",
    "        h = 60 - (self.kernel_size1 - 1)\n",
    "        w = 19 - (self.kernel_size1 - 1)\n",
    "        h = h // 2\n",
    "        w = w // 2\n",
    "        h = h - (self.kernel_size2 - 1)\n",
    "        w = w - (self.kernel_size2 - 1)\n",
    "        h = h // 2\n",
    "        w = w // 2\n",
    "        self.h = h \n",
    "        self.w = w\n",
    "        self.fc1 = nn.Linear(self.channels_out2 * h * w, self.hid_size1)\n",
    "        self.fc2 = nn.Linear(self.hid_size1, self.hid_size2)\n",
    "        self.fc3 = nn.Linear(self.hid_size2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, self.channels_out2 * self.h * self.w)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up parameters and hyper parameters\n",
    "channels_in = 1\n",
    "channels_out1 = 2\n",
    "channels_out2 = 2\n",
    "kernel_size1 = 5\n",
    "kernel_size2 = 5\n",
    "hid_size1 = 20\n",
    "hid_size2 = 20\n",
    "\n",
    "net = Net(channels_in, channels_out1, channels_out2, kernel_size1, kernel_size2, hid_size1, hid_size2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(inputs, labels, training=True):\n",
    "    \n",
    "    if training:\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels.view(-1,))\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels.view(-1,))\n",
    "    return loss, outputs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(X, y):\n",
    "    test_loss, test_outputs = get_loss(X, y, training=False)\n",
    "\n",
    "    return (test_outputs.argmax(dim=-1).view(-1) == y.view(-1)).sum().float() / y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    10] loss: 0.592 ones 25.300\n",
      "\n",
      "[1,    20] loss: 0.607 ones 26.600\n",
      "\n",
      "[1,    30] loss: 0.616 ones 27.000\n",
      "\n",
      "[1,    40] loss: 0.630 ones 27.900\n",
      "\n",
      "[1,    50] loss: 0.643 ones 25.200\n",
      "\n",
      "[1,    60] loss: 0.617 ones 27.000\n",
      "\n",
      "[1,    70] loss: 0.622 ones 25.500\n",
      "\n",
      "[1,    80] loss: 0.592 ones 25.700\n",
      "\n",
      "[1,    90] loss: 0.619 ones 26.200\n",
      "\n",
      "tensor(600)\n",
      "dev_loss is 0.7473, best_loss is 0.7473, accuracy is 0.5933\n",
      "test_loss is 0.7473, best_loss is 0.7473, accuracy is 0.6745\n",
      "[2,    10] loss: 0.621 ones 25.900\n",
      "\n",
      "[2,    20] loss: 0.592 ones 26.600\n",
      "\n",
      "[2,    30] loss: 0.648 ones 26.900\n",
      "\n",
      "[2,    40] loss: 0.581 ones 25.100\n",
      "\n",
      "[2,    50] loss: 0.596 ones 26.900\n",
      "\n",
      "[2,    60] loss: 0.623 ones 26.000\n",
      "\n",
      "[2,    70] loss: 0.633 ones 27.600\n",
      "\n",
      "[2,    80] loss: 0.629 ones 25.400\n",
      "\n",
      "[2,    90] loss: 0.595 ones 26.900\n",
      "\n",
      "tensor(600)\n",
      "dev_loss is 0.7554, best_loss is 0.7473, accuracy is 0.5933\n",
      "test_loss is 0.7554, best_loss is 0.7473, accuracy is 0.6745\n",
      "[3,    10] loss: 0.621 ones 26.500\n",
      "\n",
      "[3,    20] loss: 0.613 ones 27.700\n",
      "\n",
      "[3,    30] loss: 0.586 ones 28.100\n",
      "\n",
      "[3,    40] loss: 0.597 ones 26.900\n",
      "\n",
      "[3,    50] loss: 0.624 ones 25.900\n",
      "\n",
      "[3,    60] loss: 0.626 ones 26.300\n",
      "\n",
      "[3,    70] loss: 0.625 ones 24.300\n",
      "\n",
      "[3,    80] loss: 0.592 ones 26.600\n",
      "\n",
      "[3,    90] loss: 0.612 ones 26.000\n",
      "\n",
      "tensor(600)\n",
      "dev_loss is 0.7463, best_loss is 0.7463, accuracy is 0.5933\n",
      "test_loss is 0.7463, best_loss is 0.7463, accuracy is 0.6745\n",
      "[4,    10] loss: 0.590 ones 27.600\n",
      "\n",
      "[4,    20] loss: 0.582 ones 25.500\n",
      "\n",
      "[4,    30] loss: 0.619 ones 26.400\n",
      "\n",
      "[4,    40] loss: 0.615 ones 26.600\n",
      "\n",
      "[4,    50] loss: 0.587 ones 26.200\n",
      "\n",
      "[4,    60] loss: 0.628 ones 25.500\n",
      "\n",
      "[4,    70] loss: 0.628 ones 26.500\n",
      "\n",
      "[4,    80] loss: 0.632 ones 26.500\n",
      "\n",
      "[4,    90] loss: 0.628 ones 27.600\n",
      "\n",
      "tensor(600)\n",
      "dev_loss is 0.7415, best_loss is 0.7415, accuracy is 0.5933\n",
      "test_loss is 0.7415, best_loss is 0.7415, accuracy is 0.6745\n",
      "[5,    10] loss: 0.613 ones 26.700\n",
      "\n",
      "[5,    20] loss: 0.581 ones 25.100\n",
      "\n",
      "[5,    30] loss: 0.607 ones 27.500\n",
      "\n",
      "[5,    40] loss: 0.605 ones 27.800\n",
      "\n",
      "[5,    50] loss: 0.623 ones 27.300\n",
      "\n",
      "[5,    60] loss: 0.620 ones 25.200\n",
      "\n",
      "[5,    70] loss: 0.607 ones 27.000\n",
      "\n",
      "[5,    80] loss: 0.647 ones 25.800\n",
      "\n",
      "[5,    90] loss: 0.591 ones 26.400\n",
      "\n",
      "tensor(600)\n",
      "dev_loss is 0.7353, best_loss is 0.7353, accuracy is 0.5933\n",
      "test_loss is 0.7353, best_loss is 0.7353, accuracy is 0.6745\n",
      "[6,    10] loss: 0.605 ones 28.000\n",
      "\n",
      "[6,    20] loss: 0.636 ones 25.800\n",
      "\n",
      "[6,    30] loss: 0.608 ones 26.500\n",
      "\n",
      "[6,    40] loss: 0.588 ones 25.500\n",
      "\n",
      "[6,    50] loss: 0.586 ones 27.100\n",
      "\n",
      "[6,    60] loss: 0.580 ones 26.300\n",
      "\n",
      "[6,    70] loss: 0.620 ones 27.000\n",
      "\n",
      "[6,    80] loss: 0.626 ones 25.000\n",
      "\n",
      "[6,    90] loss: 0.641 ones 26.400\n",
      "\n",
      "tensor(600)\n",
      "dev_loss is 0.7485, best_loss is 0.7353, accuracy is 0.5933\n",
      "test_loss is 0.7485, best_loss is 0.7353, accuracy is 0.6745\n",
      "[7,    10] loss: 0.607 ones 26.100\n",
      "\n",
      "[7,    20] loss: 0.598 ones 26.600\n",
      "\n",
      "[7,    30] loss: 0.623 ones 27.700\n",
      "\n",
      "[7,    40] loss: 0.603 ones 26.400\n",
      "\n",
      "[7,    50] loss: 0.606 ones 26.100\n",
      "\n",
      "[7,    60] loss: 0.619 ones 26.600\n",
      "\n",
      "[7,    70] loss: 0.621 ones 27.700\n",
      "\n",
      "[7,    80] loss: 0.619 ones 26.100\n",
      "\n",
      "[7,    90] loss: 0.608 ones 26.800\n",
      "\n",
      "tensor(600)\n",
      "dev_loss is 0.7506, best_loss is 0.7353, accuracy is 0.5933\n",
      "test_loss is 0.7506, best_loss is 0.7353, accuracy is 0.6745\n",
      "[8,    10] loss: 0.602 ones 26.200\n",
      "\n",
      "[8,    20] loss: 0.593 ones 27.000\n",
      "\n",
      "[8,    30] loss: 0.604 ones 26.400\n",
      "\n",
      "[8,    40] loss: 0.621 ones 26.700\n",
      "\n",
      "[8,    50] loss: 0.605 ones 26.500\n",
      "\n",
      "[8,    60] loss: 0.599 ones 27.500\n",
      "\n",
      "[8,    70] loss: 0.639 ones 25.500\n",
      "\n",
      "[8,    80] loss: 0.629 ones 25.100\n",
      "\n",
      "[8,    90] loss: 0.569 ones 26.900\n",
      "\n",
      "tensor(600)\n",
      "dev_loss is 0.7595, best_loss is 0.7353, accuracy is 0.5933\n",
      "test_loss is 0.7595, best_loss is 0.7353, accuracy is 0.6745\n",
      "[9,    10] loss: 0.585 ones 26.000\n",
      "\n",
      "[9,    20] loss: 0.608 ones 28.400\n",
      "\n",
      "[9,    30] loss: 0.634 ones 26.500\n",
      "\n",
      "[9,    40] loss: 0.602 ones 26.000\n",
      "\n",
      "[9,    50] loss: 0.614 ones 26.600\n",
      "\n",
      "[9,    60] loss: 0.574 ones 25.200\n",
      "\n",
      "[9,    70] loss: 0.580 ones 25.400\n",
      "\n",
      "[9,    80] loss: 0.619 ones 26.900\n",
      "\n",
      "[9,    90] loss: 0.616 ones 26.500\n",
      "\n",
      "tensor(600)\n",
      "dev_loss is 0.7591, best_loss is 0.7353, accuracy is 0.5933\n",
      "test_loss is 0.7591, best_loss is 0.7353, accuracy is 0.6745\n",
      "[10,    10] loss: 0.606 ones 27.000\n",
      "\n",
      "[10,    20] loss: 0.625 ones 26.000\n",
      "\n",
      "[10,    30] loss: 0.612 ones 26.500\n",
      "\n",
      "[10,    40] loss: 0.591 ones 26.600\n",
      "\n",
      "[10,    50] loss: 0.622 ones 26.900\n",
      "\n",
      "[10,    60] loss: 0.588 ones 26.100\n",
      "\n",
      "[10,    70] loss: 0.625 ones 26.100\n",
      "\n",
      "[10,    80] loss: 0.587 ones 26.000\n",
      "\n",
      "[10,    90] loss: 0.591 ones 25.200\n",
      "\n",
      "tensor(600)\n",
      "dev_loss is 0.7614, best_loss is 0.7353, accuracy is 0.5933\n",
      "test_loss is 0.7614, best_loss is 0.7353, accuracy is 0.6745\n",
      "[11,    10] loss: 0.653 ones 27.400\n",
      "\n",
      "[11,    20] loss: 0.601 ones 26.300\n",
      "\n",
      "[11,    30] loss: 0.600 ones 25.100\n",
      "\n",
      "[11,    40] loss: 0.608 ones 26.600\n",
      "\n",
      "[11,    50] loss: 0.609 ones 27.100\n",
      "\n",
      "[11,    60] loss: 0.607 ones 27.100\n",
      "\n",
      "[11,    70] loss: 0.602 ones 25.800\n",
      "\n",
      "[11,    80] loss: 0.575 ones 26.700\n",
      "\n",
      "[11,    90] loss: 0.582 ones 26.300\n",
      "\n",
      "tensor(600)\n",
      "dev_loss is 0.7778, best_loss is 0.7353, accuracy is 0.5933\n",
      "test_loss is 0.7778, best_loss is 0.7353, accuracy is 0.6745\n",
      "[12,    10] loss: 0.599 ones 27.300\n",
      "\n",
      "[12,    20] loss: 0.594 ones 26.400\n",
      "\n",
      "[12,    30] loss: 0.610 ones 25.000\n",
      "\n",
      "[12,    40] loss: 0.600 ones 26.700\n",
      "\n",
      "[12,    50] loss: 0.597 ones 26.300\n",
      "\n",
      "[12,    60] loss: 0.605 ones 26.300\n",
      "\n",
      "[12,    70] loss: 0.576 ones 27.600\n",
      "\n",
      "[12,    80] loss: 0.644 ones 26.300\n",
      "\n",
      "[12,    90] loss: 0.604 ones 26.700\n",
      "\n",
      "tensor(600)\n",
      "dev_loss is 0.7510, best_loss is 0.7353, accuracy is 0.5933\n",
      "test_loss is 0.7510, best_loss is 0.7353, accuracy is 0.6745\n",
      "[13,    10] loss: 0.603 ones 27.800\n",
      "\n",
      "[13,    20] loss: 0.585 ones 25.900\n",
      "\n",
      "[13,    30] loss: 0.584 ones 26.400\n",
      "\n",
      "[13,    40] loss: 0.611 ones 26.500\n",
      "\n",
      "[13,    50] loss: 0.616 ones 26.200\n",
      "\n",
      "[13,    60] loss: 0.592 ones 26.300\n",
      "\n",
      "[13,    70] loss: 0.576 ones 25.900\n",
      "\n",
      "[13,    80] loss: 0.629 ones 26.100\n",
      "\n",
      "[13,    90] loss: 0.614 ones 27.700\n",
      "\n",
      "tensor(600)\n",
      "dev_loss is 0.7543, best_loss is 0.7353, accuracy is 0.5933\n",
      "test_loss is 0.7543, best_loss is 0.7353, accuracy is 0.6745\n",
      "[14,    10] loss: 0.578 ones 26.400\n",
      "\n",
      "[14,    20] loss: 0.598 ones 25.600\n",
      "\n",
      "[14,    30] loss: 0.623 ones 26.600\n",
      "\n",
      "[14,    40] loss: 0.604 ones 26.100\n",
      "\n",
      "[14,    50] loss: 0.595 ones 27.000\n",
      "\n",
      "[14,    60] loss: 0.573 ones 25.500\n",
      "\n",
      "[14,    70] loss: 0.623 ones 27.900\n",
      "\n",
      "[14,    80] loss: 0.614 ones 26.200\n",
      "\n",
      "[14,    90] loss: 0.609 ones 25.400\n",
      "\n",
      "tensor(600)\n",
      "dev_loss is 0.7570, best_loss is 0.7353, accuracy is 0.5933\n",
      "test_loss is 0.7570, best_loss is 0.7353, accuracy is 0.6745\n",
      "[15,    10] loss: 0.624 ones 26.800\n",
      "\n",
      "[15,    20] loss: 0.576 ones 25.800\n",
      "\n",
      "[15,    30] loss: 0.562 ones 25.600\n",
      "\n",
      "[15,    40] loss: 0.599 ones 27.100\n",
      "\n",
      "[15,    50] loss: 0.576 ones 25.000\n",
      "\n",
      "[15,    60] loss: 0.616 ones 27.000\n",
      "\n",
      "[15,    70] loss: 0.611 ones 27.600\n",
      "\n",
      "[15,    80] loss: 0.591 ones 26.900\n",
      "\n",
      "[15,    90] loss: 0.631 ones 25.400\n",
      "\n",
      "tensor(600)\n",
      "dev_loss is 0.7660, best_loss is 0.7353, accuracy is 0.5933\n",
      "test_loss is 0.7660, best_loss is 0.7353, accuracy is 0.6745\n",
      "[16,    10] loss: 0.589 ones 26.100\n",
      "\n",
      "[16,    20] loss: 0.595 ones 28.400\n",
      "\n",
      "[16,    30] loss: 0.574 ones 25.500\n",
      "\n",
      "[16,    40] loss: 0.624 ones 27.500\n",
      "\n",
      "[16,    50] loss: 0.605 ones 26.400\n",
      "\n",
      "[16,    60] loss: 0.587 ones 25.200\n",
      "\n",
      "[16,    70] loss: 0.586 ones 25.700\n",
      "\n",
      "[16,    80] loss: 0.574 ones 24.900\n",
      "\n",
      "[16,    90] loss: 0.610 ones 26.500\n",
      "\n",
      "tensor(600)\n",
      "dev_loss is 0.7798, best_loss is 0.7353, accuracy is 0.5933\n",
      "test_loss is 0.7798, best_loss is 0.7353, accuracy is 0.6745\n",
      "[17,    10] loss: 0.577 ones 28.000\n",
      "\n",
      "[17,    20] loss: 0.574 ones 26.700\n",
      "\n",
      "[17,    30] loss: 0.645 ones 26.600\n",
      "\n",
      "[17,    40] loss: 0.596 ones 24.500\n",
      "\n",
      "[17,    50] loss: 0.580 ones 26.700\n",
      "\n",
      "[17,    60] loss: 0.599 ones 25.700\n",
      "\n",
      "[17,    70] loss: 0.624 ones 27.000\n",
      "\n",
      "[17,    80] loss: 0.582 ones 25.900\n",
      "\n",
      "[17,    90] loss: 0.595 ones 26.600\n",
      "\n",
      "tensor(600)\n",
      "dev_loss is 0.7512, best_loss is 0.7353, accuracy is 0.5933\n",
      "test_loss is 0.7512, best_loss is 0.7353, accuracy is 0.6745\n",
      "[18,    10] loss: 0.581 ones 25.800\n",
      "\n",
      "[18,    20] loss: 0.573 ones 27.000\n",
      "\n",
      "[18,    30] loss: 0.631 ones 27.700\n",
      "\n",
      "[18,    40] loss: 0.577 ones 25.400\n",
      "\n",
      "[18,    50] loss: 0.592 ones 26.000\n",
      "\n",
      "[18,    60] loss: 0.598 ones 25.600\n",
      "\n",
      "[18,    70] loss: 0.617 ones 26.600\n",
      "\n",
      "[18,    80] loss: 0.593 ones 26.900\n",
      "\n",
      "[18,    90] loss: 0.581 ones 26.700\n",
      "\n",
      "tensor(600)\n",
      "dev_loss is 0.7716, best_loss is 0.7353, accuracy is 0.5933\n",
      "test_loss is 0.7716, best_loss is 0.7353, accuracy is 0.6745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19,    10] loss: 0.606 ones 26.700\n",
      "\n",
      "[19,    20] loss: 0.540 ones 26.400\n",
      "\n",
      "[19,    30] loss: 0.581 ones 25.700\n",
      "\n",
      "[19,    40] loss: 0.578 ones 25.700\n",
      "\n",
      "[19,    50] loss: 0.589 ones 26.700\n",
      "\n",
      "[19,    60] loss: 0.605 ones 26.800\n",
      "\n",
      "[19,    70] loss: 0.609 ones 25.900\n",
      "\n",
      "[19,    80] loss: 0.605 ones 26.300\n",
      "\n",
      "[19,    90] loss: 0.618 ones 26.900\n",
      "\n",
      "tensor(600)\n",
      "dev_loss is 0.7601, best_loss is 0.7353, accuracy is 0.5933\n",
      "test_loss is 0.7601, best_loss is 0.7353, accuracy is 0.6745\n",
      "[20,    10] loss: 0.615 ones 26.300\n",
      "\n",
      "[20,    20] loss: 0.594 ones 25.900\n",
      "\n",
      "[20,    30] loss: 0.596 ones 24.900\n",
      "\n",
      "[20,    40] loss: 0.575 ones 26.900\n",
      "\n",
      "[20,    50] loss: 0.594 ones 27.100\n",
      "\n",
      "[20,    60] loss: 0.616 ones 25.400\n",
      "\n",
      "[20,    70] loss: 0.577 ones 25.500\n",
      "\n",
      "[20,    80] loss: 0.567 ones 26.800\n",
      "\n",
      "[20,    90] loss: 0.581 ones 27.400\n",
      "\n",
      "tensor(600)\n",
      "dev_loss is 0.7885, best_loss is 0.7353, accuracy is 0.5933\n",
      "test_loss is 0.7885, best_loss is 0.7353, accuracy is 0.6745\n",
      "[21,    10] loss: 0.586 ones 27.100\n",
      "\n",
      "[21,    20] loss: 0.586 ones 27.100\n",
      "\n",
      "[21,    30] loss: 0.565 ones 26.700\n",
      "\n",
      "[21,    40] loss: 0.618 ones 26.600\n",
      "\n",
      "[21,    50] loss: 0.578 ones 24.700\n",
      "\n",
      "[21,    60] loss: 0.549 ones 26.700\n",
      "\n",
      "[21,    70] loss: 0.610 ones 25.900\n",
      "\n",
      "[21,    80] loss: 0.617 ones 24.300\n",
      "\n",
      "[21,    90] loss: 0.620 ones 26.600\n",
      "\n",
      "tensor(600)\n",
      "dev_loss is 0.7358, best_loss is 0.7353, accuracy is 0.5933\n",
      "test_loss is 0.7358, best_loss is 0.7353, accuracy is 0.6745\n",
      "[22,    10] loss: 0.617 ones 26.500\n",
      "\n",
      "[22,    20] loss: 0.596 ones 25.100\n",
      "\n",
      "[22,    30] loss: 0.572 ones 25.500\n",
      "\n",
      "[22,    40] loss: 0.587 ones 25.200\n",
      "\n",
      "[22,    50] loss: 0.595 ones 27.800\n",
      "\n",
      "[22,    60] loss: 0.590 ones 25.200\n",
      "\n",
      "[22,    70] loss: 0.583 ones 27.500\n",
      "\n",
      "[22,    80] loss: 0.597 ones 26.600\n",
      "\n",
      "[22,    90] loss: 0.563 ones 25.800\n",
      "\n",
      "tensor(600)\n",
      "dev_loss is 0.8223, best_loss is 0.7353, accuracy is 0.5933\n",
      "test_loss is 0.8223, best_loss is 0.7353, accuracy is 0.6745\n",
      "[23,    10] loss: 0.584 ones 27.100\n",
      "\n",
      "[23,    20] loss: 0.587 ones 27.100\n",
      "\n",
      "[23,    30] loss: 0.594 ones 26.500\n",
      "\n",
      "[23,    40] loss: 0.547 ones 23.800\n",
      "\n",
      "[23,    50] loss: 0.595 ones 27.900\n",
      "\n",
      "[23,    60] loss: 0.602 ones 27.400\n",
      "\n",
      "[23,    70] loss: 0.568 ones 26.500\n",
      "\n",
      "[23,    80] loss: 0.580 ones 25.600\n",
      "\n",
      "[23,    90] loss: 0.610 ones 25.200\n",
      "\n",
      "tensor(600)\n",
      "dev_loss is 0.7539, best_loss is 0.7353, accuracy is 0.5933\n",
      "test_loss is 0.7539, best_loss is 0.7353, accuracy is 0.6686\n",
      "[24,    10] loss: 0.598 ones 25.600\n",
      "\n",
      "[24,    20] loss: 0.576 ones 27.200\n",
      "\n",
      "[24,    30] loss: 0.610 ones 26.600\n",
      "\n",
      "[24,    40] loss: 0.575 ones 25.500\n",
      "\n",
      "[24,    50] loss: 0.544 ones 26.600\n",
      "\n",
      "[24,    60] loss: 0.616 ones 25.300\n",
      "\n",
      "[24,    70] loss: 0.607 ones 26.800\n",
      "\n",
      "[24,    80] loss: 0.554 ones 27.700\n",
      "\n",
      "[24,    90] loss: 0.581 ones 26.700\n",
      "\n",
      "tensor(600)\n",
      "dev_loss is 0.7676, best_loss is 0.7353, accuracy is 0.5933\n",
      "test_loss is 0.7676, best_loss is 0.7353, accuracy is 0.6657\n",
      "[25,    10] loss: 0.589 ones 24.100\n",
      "\n",
      "[25,    20] loss: 0.574 ones 25.000\n",
      "\n",
      "[25,    30] loss: 0.591 ones 27.400\n",
      "\n",
      "[25,    40] loss: 0.548 ones 25.100\n",
      "\n",
      "[25,    50] loss: 0.600 ones 25.000\n",
      "\n",
      "[25,    60] loss: 0.581 ones 25.700\n",
      "\n",
      "[25,    70] loss: 0.586 ones 28.200\n",
      "\n",
      "[25,    80] loss: 0.577 ones 26.700\n",
      "\n",
      "[25,    90] loss: 0.560 ones 25.300\n",
      "\n",
      "tensor(600)\n",
      "dev_loss is 0.7789, best_loss is 0.7353, accuracy is 0.5933\n",
      "test_loss is 0.7789, best_loss is 0.7353, accuracy is 0.6657\n",
      "[26,    10] loss: 0.582 ones 26.100\n",
      "\n",
      "[26,    20] loss: 0.586 ones 27.300\n",
      "\n",
      "[26,    30] loss: 0.586 ones 26.600\n",
      "\n",
      "[26,    40] loss: 0.586 ones 25.900\n",
      "\n",
      "[26,    50] loss: 0.592 ones 25.400\n",
      "\n",
      "[26,    60] loss: 0.563 ones 25.900\n",
      "\n",
      "[26,    70] loss: 0.574 ones 26.800\n",
      "\n",
      "[26,    80] loss: 0.572 ones 26.300\n",
      "\n",
      "[26,    90] loss: 0.563 ones 24.600\n",
      "\n",
      "tensor(600)\n",
      "dev_loss is 0.7966, best_loss is 0.7353, accuracy is 0.5933\n",
      "test_loss is 0.7966, best_loss is 0.7353, accuracy is 0.6642\n",
      "[27,    10] loss: 0.579 ones 25.900\n",
      "\n",
      "[27,    20] loss: 0.585 ones 23.600\n",
      "\n",
      "[27,    30] loss: 0.564 ones 26.200\n",
      "\n",
      "[27,    40] loss: 0.574 ones 26.300\n",
      "\n",
      "[27,    50] loss: 0.576 ones 27.100\n",
      "\n",
      "[27,    60] loss: 0.593 ones 28.000\n",
      "\n",
      "[27,    70] loss: 0.560 ones 26.900\n",
      "\n",
      "[27,    80] loss: 0.581 ones 25.800\n",
      "\n",
      "[27,    90] loss: 0.560 ones 26.300\n",
      "\n",
      "tensor(598)\n",
      "dev_loss is 0.7621, best_loss is 0.7353, accuracy is 0.5933\n",
      "test_loss is 0.7621, best_loss is 0.7353, accuracy is 0.6525\n",
      "[28,    10] loss: 0.573 ones 24.200\n",
      "\n",
      "[28,    20] loss: 0.594 ones 26.400\n",
      "\n",
      "[28,    30] loss: 0.562 ones 26.300\n",
      "\n",
      "[28,    40] loss: 0.565 ones 24.400\n",
      "\n",
      "[28,    50] loss: 0.602 ones 24.800\n",
      "\n",
      "[28,    60] loss: 0.601 ones 27.500\n",
      "\n",
      "[28,    70] loss: 0.566 ones 28.100\n",
      "\n",
      "[28,    80] loss: 0.541 ones 25.200\n",
      "\n",
      "[28,    90] loss: 0.551 ones 25.800\n",
      "\n",
      "tensor(600)\n",
      "dev_loss is 0.8162, best_loss is 0.7353, accuracy is 0.5933\n",
      "test_loss is 0.8162, best_loss is 0.7353, accuracy is 0.6554\n",
      "[29,    10] loss: 0.585 ones 24.900\n",
      "\n",
      "[29,    20] loss: 0.581 ones 26.500\n",
      "\n",
      "[29,    30] loss: 0.572 ones 26.400\n",
      "\n",
      "[29,    40] loss: 0.585 ones 27.100\n",
      "\n",
      "[29,    50] loss: 0.556 ones 25.800\n",
      "\n",
      "[29,    60] loss: 0.527 ones 25.200\n",
      "\n",
      "[29,    70] loss: 0.565 ones 24.700\n",
      "\n",
      "[29,    80] loss: 0.579 ones 24.500\n",
      "\n",
      "[29,    90] loss: 0.573 ones 27.000\n",
      "\n",
      "tensor(600)\n",
      "dev_loss is 0.8039, best_loss is 0.7353, accuracy is 0.5933\n",
      "test_loss is 0.8039, best_loss is 0.7353, accuracy is 0.6452\n",
      "[30,    10] loss: 0.554 ones 26.400\n",
      "\n",
      "[30,    20] loss: 0.529 ones 25.200\n",
      "\n",
      "[30,    30] loss: 0.571 ones 26.400\n",
      "\n",
      "[30,    40] loss: 0.574 ones 25.200\n",
      "\n",
      "[30,    50] loss: 0.586 ones 24.200\n",
      "\n",
      "[30,    60] loss: 0.560 ones 24.700\n",
      "\n",
      "[30,    70] loss: 0.580 ones 28.000\n",
      "\n",
      "[30,    80] loss: 0.568 ones 26.000\n",
      "\n",
      "[30,    90] loss: 0.582 ones 25.500\n",
      "\n",
      "tensor(597)\n",
      "dev_loss is 0.8131, best_loss is 0.7353, accuracy is 0.5950\n",
      "test_loss is 0.8131, best_loss is 0.7353, accuracy is 0.6408\n",
      "[31,    10] loss: 0.533 ones 24.700\n",
      "\n",
      "[31,    20] loss: 0.564 ones 25.300\n",
      "\n",
      "[31,    30] loss: 0.537 ones 26.100\n",
      "\n",
      "[31,    40] loss: 0.540 ones 25.500\n",
      "\n",
      "[31,    50] loss: 0.571 ones 26.800\n",
      "\n",
      "[31,    60] loss: 0.546 ones 26.900\n",
      "\n",
      "[31,    70] loss: 0.607 ones 27.400\n",
      "\n",
      "[31,    80] loss: 0.560 ones 24.200\n",
      "\n",
      "[31,    90] loss: 0.585 ones 25.600\n",
      "\n",
      "tensor(588)\n",
      "dev_loss is 0.7866, best_loss is 0.7353, accuracy is 0.5933\n",
      "test_loss is 0.7866, best_loss is 0.7353, accuracy is 0.6217\n",
      "[32,    10] loss: 0.550 ones 26.800\n",
      "\n",
      "[32,    20] loss: 0.520 ones 26.600\n",
      "\n",
      "[32,    30] loss: 0.538 ones 25.200\n",
      "\n",
      "[32,    40] loss: 0.569 ones 26.900\n",
      "\n",
      "[32,    50] loss: 0.540 ones 26.400\n",
      "\n",
      "[32,    60] loss: 0.557 ones 25.700\n",
      "\n",
      "[32,    70] loss: 0.574 ones 26.400\n",
      "\n",
      "[32,    80] loss: 0.573 ones 24.900\n",
      "\n",
      "[32,    90] loss: 0.557 ones 22.700\n",
      "\n",
      "tensor(581)\n",
      "dev_loss is 0.8019, best_loss is 0.7353, accuracy is 0.5850\n",
      "test_loss is 0.8019, best_loss is 0.7353, accuracy is 0.6202\n",
      "[33,    10] loss: 0.516 ones 25.000\n",
      "\n",
      "[33,    20] loss: 0.568 ones 25.100\n",
      "\n",
      "[33,    30] loss: 0.511 ones 25.700\n",
      "\n",
      "[33,    40] loss: 0.539 ones 26.000\n",
      "\n",
      "[33,    50] loss: 0.570 ones 25.200\n",
      "\n",
      "[33,    60] loss: 0.564 ones 23.100\n",
      "\n",
      "[33,    70] loss: 0.595 ones 24.100\n",
      "\n",
      "[33,    80] loss: 0.548 ones 25.200\n",
      "\n",
      "[33,    90] loss: 0.558 ones 26.100\n",
      "\n",
      "tensor(598)\n",
      "dev_loss is 0.8858, best_loss is 0.7353, accuracy is 0.5933\n",
      "test_loss is 0.8858, best_loss is 0.7353, accuracy is 0.6276\n",
      "[34,    10] loss: 0.531 ones 27.700\n",
      "\n",
      "[34,    20] loss: 0.567 ones 25.600\n",
      "\n",
      "[34,    30] loss: 0.531 ones 25.000\n",
      "\n",
      "[34,    40] loss: 0.546 ones 25.400\n",
      "\n",
      "[34,    50] loss: 0.522 ones 26.500\n",
      "\n",
      "[34,    60] loss: 0.606 ones 26.200\n",
      "\n",
      "[34,    70] loss: 0.537 ones 25.500\n",
      "\n",
      "[34,    80] loss: 0.552 ones 24.800\n",
      "\n",
      "[34,    90] loss: 0.524 ones 24.000\n",
      "\n",
      "tensor(582)\n",
      "dev_loss is 0.8357, best_loss is 0.7353, accuracy is 0.5933\n",
      "test_loss is 0.8357, best_loss is 0.7353, accuracy is 0.6100\n",
      "[35,    10] loss: 0.514 ones 26.100\n",
      "\n",
      "[35,    20] loss: 0.546 ones 23.400\n",
      "\n",
      "[35,    30] loss: 0.552 ones 24.600\n",
      "\n",
      "[35,    40] loss: 0.529 ones 24.800\n",
      "\n",
      "[35,    50] loss: 0.540 ones 24.900\n",
      "\n",
      "[35,    60] loss: 0.522 ones 25.300\n",
      "\n",
      "[35,    70] loss: 0.534 ones 26.800\n",
      "\n",
      "[35,    80] loss: 0.581 ones 26.500\n",
      "\n",
      "[35,    90] loss: 0.552 ones 25.400\n",
      "\n",
      "tensor(529)\n",
      "dev_loss is 0.7791, best_loss is 0.7353, accuracy is 0.5717\n",
      "test_loss is 0.7791, best_loss is 0.7353, accuracy is 0.5997\n",
      "[36,    10] loss: 0.508 ones 23.900\n",
      "\n",
      "[36,    20] loss: 0.531 ones 24.200\n",
      "\n",
      "[36,    30] loss: 0.597 ones 21.900\n",
      "\n",
      "[36,    40] loss: 0.557 ones 23.900\n",
      "\n",
      "[36,    50] loss: 0.564 ones 25.200\n",
      "\n",
      "[36,    60] loss: 0.540 ones 25.200\n",
      "\n",
      "[36,    70] loss: 0.529 ones 25.000\n",
      "\n",
      "[36,    80] loss: 0.524 ones 25.700\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36,    90] loss: 0.523 ones 26.100\n",
      "\n",
      "tensor(581)\n",
      "dev_loss is 0.8955, best_loss is 0.7353, accuracy is 0.5950\n",
      "test_loss is 0.8955, best_loss is 0.7353, accuracy is 0.6246\n",
      "[37,    10] loss: 0.522 ones 26.400\n",
      "\n",
      "[37,    20] loss: 0.562 ones 25.700\n",
      "\n",
      "[37,    30] loss: 0.536 ones 25.600\n",
      "\n",
      "[37,    40] loss: 0.560 ones 25.000\n",
      "\n",
      "[37,    50] loss: 0.501 ones 24.900\n",
      "\n",
      "[37,    60] loss: 0.527 ones 24.900\n",
      "\n",
      "[37,    70] loss: 0.556 ones 24.800\n",
      "\n",
      "[37,    80] loss: 0.535 ones 24.100\n",
      "\n",
      "[37,    90] loss: 0.525 ones 24.900\n",
      "\n",
      "tensor(573)\n",
      "dev_loss is 0.8595, best_loss is 0.7353, accuracy is 0.5983\n",
      "test_loss is 0.8595, best_loss is 0.7353, accuracy is 0.6085\n",
      "[38,    10] loss: 0.491 ones 23.900\n",
      "\n",
      "[38,    20] loss: 0.519 ones 21.800\n",
      "\n",
      "[38,    30] loss: 0.555 ones 24.300\n",
      "\n",
      "[38,    40] loss: 0.552 ones 24.900\n",
      "\n",
      "[38,    50] loss: 0.517 ones 23.000\n",
      "\n",
      "[38,    60] loss: 0.526 ones 24.800\n",
      "\n",
      "[38,    70] loss: 0.537 ones 25.900\n",
      "\n",
      "[38,    80] loss: 0.540 ones 25.200\n",
      "\n",
      "[38,    90] loss: 0.512 ones 25.900\n",
      "\n",
      "tensor(578)\n",
      "dev_loss is 0.8985, best_loss is 0.7353, accuracy is 0.5967\n",
      "test_loss is 0.8985, best_loss is 0.7353, accuracy is 0.5997\n",
      "[39,    10] loss: 0.551 ones 26.300\n",
      "\n",
      "[39,    20] loss: 0.515 ones 24.300\n",
      "\n",
      "[39,    30] loss: 0.524 ones 25.900\n",
      "\n",
      "[39,    40] loss: 0.519 ones 24.400\n",
      "\n",
      "[39,    50] loss: 0.536 ones 23.600\n",
      "\n",
      "[39,    60] loss: 0.523 ones 22.800\n",
      "\n",
      "[39,    70] loss: 0.529 ones 24.400\n",
      "\n",
      "[39,    80] loss: 0.574 ones 25.100\n",
      "\n",
      "[39,    90] loss: 0.499 ones 25.500\n",
      "\n",
      "tensor(580)\n",
      "dev_loss is 0.9211, best_loss is 0.7353, accuracy is 0.5967\n",
      "test_loss is 0.9211, best_loss is 0.7353, accuracy is 0.6100\n",
      "[40,    10] loss: 0.534 ones 26.200\n",
      "\n",
      "[40,    20] loss: 0.534 ones 21.500\n",
      "\n",
      "[40,    30] loss: 0.502 ones 22.800\n",
      "\n",
      "[40,    40] loss: 0.553 ones 24.700\n",
      "\n",
      "[40,    50] loss: 0.505 ones 24.800\n",
      "\n",
      "[40,    60] loss: 0.510 ones 24.700\n",
      "\n",
      "[40,    70] loss: 0.507 ones 25.600\n",
      "\n",
      "[40,    80] loss: 0.576 ones 24.000\n",
      "\n",
      "[40,    90] loss: 0.526 ones 23.000\n",
      "\n",
      "tensor(561)\n",
      "dev_loss is 0.8781, best_loss is 0.7353, accuracy is 0.5883\n",
      "test_loss is 0.8781, best_loss is 0.7353, accuracy is 0.6056\n",
      "[41,    10] loss: 0.491 ones 24.800\n",
      "\n",
      "[41,    20] loss: 0.501 ones 23.500\n",
      "\n",
      "[41,    30] loss: 0.567 ones 26.300\n",
      "\n",
      "[41,    40] loss: 0.545 ones 25.700\n",
      "\n",
      "[41,    50] loss: 0.563 ones 25.700\n",
      "\n",
      "[41,    60] loss: 0.495 ones 23.000\n",
      "\n",
      "[41,    70] loss: 0.513 ones 23.600\n",
      "\n",
      "[41,    80] loss: 0.528 ones 25.000\n",
      "\n",
      "[41,    90] loss: 0.501 ones 23.400\n",
      "\n",
      "tensor(569)\n",
      "dev_loss is 0.9185, best_loss is 0.7353, accuracy is 0.5950\n",
      "test_loss is 0.9185, best_loss is 0.7353, accuracy is 0.5953\n",
      "[42,    10] loss: 0.505 ones 25.400\n",
      "\n",
      "[42,    20] loss: 0.544 ones 24.700\n",
      "\n",
      "[42,    30] loss: 0.529 ones 24.600\n",
      "\n",
      "[42,    40] loss: 0.524 ones 24.800\n",
      "\n",
      "[42,    50] loss: 0.521 ones 24.700\n",
      "\n",
      "[42,    60] loss: 0.509 ones 22.800\n",
      "\n",
      "[42,    70] loss: 0.497 ones 22.200\n",
      "\n",
      "[42,    80] loss: 0.526 ones 22.500\n",
      "\n",
      "[42,    90] loss: 0.505 ones 24.500\n",
      "\n",
      "tensor(563)\n",
      "dev_loss is 0.9162, best_loss is 0.7353, accuracy is 0.5983\n",
      "test_loss is 0.9162, best_loss is 0.7353, accuracy is 0.6041\n",
      "[43,    10] loss: 0.505 ones 25.300\n",
      "\n",
      "[43,    20] loss: 0.527 ones 23.100\n",
      "\n",
      "[43,    30] loss: 0.455 ones 23.800\n",
      "\n",
      "[43,    40] loss: 0.531 ones 24.000\n",
      "\n",
      "[43,    50] loss: 0.523 ones 24.000\n",
      "\n",
      "[43,    60] loss: 0.564 ones 24.100\n",
      "\n",
      "[43,    70] loss: 0.461 ones 23.300\n",
      "\n",
      "[43,    80] loss: 0.562 ones 24.700\n",
      "\n",
      "[43,    90] loss: 0.537 ones 23.700\n",
      "\n",
      "tensor(521)\n",
      "dev_loss is 0.8720, best_loss is 0.7353, accuracy is 0.5550\n",
      "test_loss is 0.8720, best_loss is 0.7353, accuracy is 0.5968\n",
      "[44,    10] loss: 0.532 ones 23.100\n",
      "\n",
      "[44,    20] loss: 0.484 ones 24.800\n",
      "\n",
      "[44,    30] loss: 0.542 ones 22.700\n",
      "\n",
      "[44,    40] loss: 0.487 ones 21.100\n",
      "\n",
      "[44,    50] loss: 0.524 ones 24.000\n",
      "\n",
      "[44,    60] loss: 0.516 ones 26.100\n",
      "\n",
      "[44,    70] loss: 0.491 ones 25.900\n",
      "\n",
      "[44,    80] loss: 0.505 ones 25.900\n",
      "\n",
      "[44,    90] loss: 0.504 ones 23.500\n",
      "\n",
      "tensor(542)\n",
      "dev_loss is 0.9086, best_loss is 0.7353, accuracy is 0.5667\n",
      "test_loss is 0.9086, best_loss is 0.7353, accuracy is 0.5880\n",
      "[45,    10] loss: 0.510 ones 22.200\n",
      "\n",
      "[45,    20] loss: 0.514 ones 24.400\n",
      "\n",
      "[45,    30] loss: 0.462 ones 24.000\n",
      "\n",
      "[45,    40] loss: 0.512 ones 23.700\n",
      "\n",
      "[45,    50] loss: 0.509 ones 21.300\n",
      "\n",
      "[45,    60] loss: 0.519 ones 22.700\n",
      "\n",
      "[45,    70] loss: 0.554 ones 25.700\n",
      "\n",
      "[45,    80] loss: 0.507 ones 23.600\n",
      "\n",
      "[45,    90] loss: 0.484 ones 23.800\n",
      "\n",
      "tensor(575)\n",
      "dev_loss is 0.9967, best_loss is 0.7353, accuracy is 0.5983\n",
      "test_loss is 0.9967, best_loss is 0.7353, accuracy is 0.5982\n",
      "[46,    10] loss: 0.506 ones 24.400\n",
      "\n",
      "[46,    20] loss: 0.482 ones 20.700\n",
      "\n",
      "[46,    30] loss: 0.524 ones 24.700\n",
      "\n",
      "[46,    40] loss: 0.510 ones 25.300\n",
      "\n",
      "[46,    50] loss: 0.524 ones 24.400\n",
      "\n",
      "[46,    60] loss: 0.506 ones 23.900\n",
      "\n",
      "[46,    70] loss: 0.503 ones 23.000\n",
      "\n",
      "[46,    80] loss: 0.516 ones 25.000\n",
      "\n",
      "[46,    90] loss: 0.497 ones 23.400\n",
      "\n",
      "tensor(552)\n",
      "dev_loss is 0.9205, best_loss is 0.7353, accuracy is 0.5833\n",
      "test_loss is 0.9205, best_loss is 0.7353, accuracy is 0.5953\n",
      "[47,    10] loss: 0.484 ones 22.000\n",
      "\n",
      "[47,    20] loss: 0.514 ones 21.800\n",
      "\n",
      "[47,    30] loss: 0.518 ones 24.500\n",
      "\n",
      "[47,    40] loss: 0.514 ones 24.000\n",
      "\n",
      "[47,    50] loss: 0.504 ones 22.900\n",
      "\n",
      "[47,    60] loss: 0.526 ones 24.900\n",
      "\n",
      "[47,    70] loss: 0.493 ones 24.300\n",
      "\n",
      "[47,    80] loss: 0.463 ones 23.100\n",
      "\n",
      "[47,    90] loss: 0.525 ones 25.400\n",
      "\n",
      "tensor(552)\n",
      "dev_loss is 0.9334, best_loss is 0.7353, accuracy is 0.5833\n",
      "test_loss is 0.9334, best_loss is 0.7353, accuracy is 0.5894\n",
      "[48,    10] loss: 0.512 ones 22.500\n",
      "\n",
      "[48,    20] loss: 0.477 ones 23.400\n",
      "\n",
      "[48,    30] loss: 0.509 ones 23.700\n",
      "\n",
      "[48,    40] loss: 0.508 ones 22.700\n",
      "\n",
      "[48,    50] loss: 0.504 ones 25.300\n",
      "\n",
      "[48,    60] loss: 0.521 ones 24.100\n",
      "\n",
      "[48,    70] loss: 0.504 ones 23.400\n",
      "\n",
      "[48,    80] loss: 0.507 ones 23.100\n",
      "\n",
      "[48,    90] loss: 0.485 ones 22.100\n",
      "\n",
      "tensor(559)\n",
      "dev_loss is 0.9640, best_loss is 0.7353, accuracy is 0.5883\n",
      "test_loss is 0.9640, best_loss is 0.7353, accuracy is 0.5968\n",
      "[49,    10] loss: 0.466 ones 24.600\n",
      "\n",
      "[49,    20] loss: 0.523 ones 24.200\n",
      "\n",
      "[49,    30] loss: 0.514 ones 21.600\n",
      "\n",
      "[49,    40] loss: 0.508 ones 22.400\n",
      "\n",
      "[49,    50] loss: 0.467 ones 23.300\n",
      "\n",
      "[49,    60] loss: 0.510 ones 24.700\n",
      "\n",
      "[49,    70] loss: 0.508 ones 22.800\n",
      "\n",
      "[49,    80] loss: 0.501 ones 22.000\n",
      "\n",
      "[49,    90] loss: 0.503 ones 24.600\n",
      "\n",
      "tensor(559)\n",
      "dev_loss is 0.9683, best_loss is 0.7353, accuracy is 0.5883\n",
      "test_loss is 0.9683, best_loss is 0.7353, accuracy is 0.6012\n",
      "[50,    10] loss: 0.529 ones 23.600\n",
      "\n",
      "[50,    20] loss: 0.485 ones 24.100\n",
      "\n",
      "[50,    30] loss: 0.518 ones 24.000\n",
      "\n",
      "[50,    40] loss: 0.479 ones 21.500\n",
      "\n",
      "[50,    50] loss: 0.488 ones 22.500\n",
      "\n",
      "[50,    60] loss: 0.450 ones 23.000\n",
      "\n",
      "[50,    70] loss: 0.494 ones 25.600\n",
      "\n",
      "[50,    80] loss: 0.524 ones 22.200\n",
      "\n",
      "[50,    90] loss: 0.504 ones 23.000\n",
      "\n",
      "tensor(545)\n",
      "dev_loss is 0.9618, best_loss is 0.7353, accuracy is 0.5617\n",
      "test_loss is 0.9618, best_loss is 0.7353, accuracy is 0.5792\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "\n",
    "best_loss = np.inf\n",
    "lst_dev_accuracy = []\n",
    "lst_test_accuracy = []\n",
    "for epoch in range(50):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    all_outputs = 0.0\n",
    "    for i, data in enumerate(train_loader, 1):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        loss, outputs = get_loss(inputs, labels, training=True)\n",
    "        all_outputs += (outputs[:, 1] >= outputs[:, 0]).sum().item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        check_freq = 10\n",
    "        if i % check_freq == 0:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f ones %.3f' %\n",
    "                  (epoch + 1, i, running_loss / float(check_freq), all_outputs / float(check_freq)))\n",
    "            running_loss = 0.0\n",
    "            print()\n",
    "            all_outputs = 0.0\n",
    "            \n",
    "    # evaluate on dev set\n",
    "    \n",
    "    dev_loss, outputs = get_loss(X_dev, y_dev, training=False)\n",
    "    test_loss, test_outputs = get_loss(X_test, y_test, training=False)\n",
    "    dev_loss = dev_loss.item()\n",
    "    test_loss = test_loss.item()\n",
    "    \n",
    "\n",
    "    \n",
    "    print((outputs[:, 1] > outputs[:, 0]).sum())\n",
    "    if dev_loss < best_loss:\n",
    "        best_params = deepcopy(net.state_dict())\n",
    "        best_loss = dev_loss\n",
    "    accuracy_dev = get_accuracy(X_dev, y_dev)\n",
    "    accuracy_test = get_accuracy(X_test, y_test)\n",
    "    \n",
    "    lst_dev_accuracy.append(accuracy_dev)\n",
    "    lst_test_accuracy.append(accuracy_test)\n",
    "    \n",
    "    print('dev_loss is %.4f, best_loss is %.4f, accuracy is %.4f' %(dev_loss, best_loss, accuracy_dev))\n",
    "    print('test_loss is %.4f, best_loss is %.4f, accuracy is %.4f' %(dev_loss, best_loss, accuracy_test))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 2, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(2, 2, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=24, out_features=20, bias=True)\n",
       "  (fc2): Linear(in_features=20, out_features=20, bias=True)\n",
       "  (fc3): Linear(in_features=20, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.asarray([t.item() for t in lst_test_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.asarray([t.item() for t in lst_dev_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(x)), x)\n",
    "plt.plot(range(len(x)), y)\n",
    "         \n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Test Accuracy', 'Development Accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(y).index(y.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6085044145584106"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(x)[36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5983333587646484"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(y)[36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": "8f07c9a1971b4e588789be3d7b121ae5",
   "lastKernelId": "34633237-422a-467d-b152-79e365906c5e"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
